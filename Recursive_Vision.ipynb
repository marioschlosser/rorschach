{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPUAkgJ6jB7Uh4xiaz1ZRN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marioschlosser/rorschach/blob/main/Recursive_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hjE3ipLJnSW"
      },
      "outputs": [],
      "source": [
        "# @title Initialize OpenAI\n",
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "!pip install opencv-python\n",
        "\n",
        "import openai\n",
        "import tiktoken\n",
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import random\n",
        "import base64\n",
        "\n",
        "openai_key = \"\" # @param {type:\"string\"}\n",
        "openai.api_key = openai_key\n",
        "\n",
        "tokenizer = tiktoken.encoding_for_model(\"gpt-4\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image: PIL image to be described\n",
        "# prompt: prompt to the vision model asking to describe the image\n",
        "# index: number of recursion steps left\n",
        "\n",
        "def recursive_rorschach(image, prompt, index):\n",
        "  print(\"Step: \", index)\n",
        "\n",
        "  image_bytes = BytesIO()\n",
        "  image.save(image_bytes, format=\"png\")\n",
        "  base64_image = base64.b64encode(image_bytes.getvalue()).decode('utf-8')\n",
        "\n",
        "  # get image description from GPT-4V\n",
        "  response = openai.chat.completions.create(\n",
        "      model=\"gpt-4-vision-preview\",\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": [\n",
        "                  {\"type\": \"text\", \"text\": prompt},\n",
        "                  {\n",
        "                      \"type\": \"image_url\",\n",
        "                      \"image_url\": { \"url\": f\"data:image/jpeg;base64,{base64_image}\" },\n",
        "                  },\n",
        "              ],\n",
        "          }\n",
        "      ],\n",
        "      max_tokens=800,\n",
        "  )\n",
        "\n",
        "  # extract the image description\n",
        "  prompt_image = response.choices[0].message.content\n",
        "\n",
        "  print(\"Extracted prompt: \", prompt_image)\n",
        "\n",
        "  # generate the replicated image\n",
        "  response = openai.images.generate(\n",
        "    model=\"dall-e-3\",\n",
        "    prompt=prompt_image,\n",
        "    size=\"1024x1024\",\n",
        "    quality=\"standard\",\n",
        "    n=1,\n",
        "  )\n",
        "\n",
        "  # get the image\n",
        "  image_url = response.data[0].url\n",
        "\n",
        "  response = requests.get(image_url)\n",
        "  new_image = Image.open(BytesIO(response.content))\n",
        "\n",
        "  # stop the recursion if we're at the end\n",
        "  if (index == 1):\n",
        "    return [{\"image\": new_image, \"prompt\": prompt_image}]\n",
        "\n",
        "  image_list = recursive_rorschach(new_image, prompt, index - 1)\n",
        "\n",
        "  # insert the new image at the front of the list\n",
        "  image_list.insert(0, {\"image\": new_image, \"prompt\": prompt_image})\n",
        "  return image_list"
      ],
      "metadata": {
        "id": "8x4YffeEWBEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Upload the initial image...\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "img_bytes = list(uploaded.values())[0]\n",
        "initial_image = Image.open(BytesIO(img_bytes))"
      ],
      "metadata": {
        "id": "c5mrFD-JUXm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ...Or create an initial image\n",
        "\n",
        "prompt_initial_image = \"A tiny, clean white dot in the corner of a uniform blue background.\" # @param {type:\"string\"}\n",
        "\n",
        "# generate an image\n",
        "response = openai.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt=prompt_initial_image,\n",
        "  size=\"1024x1024\",\n",
        "  quality=\"standard\",\n",
        "  n=1,\n",
        ")\n",
        "\n",
        "# get the image\n",
        "image_url = response.data[0].url\n",
        "\n",
        "response = requests.get(image_url)\n",
        "initial_image = Image.open(BytesIO(response.content))"
      ],
      "metadata": {
        "id": "N-2Fj_AkYIoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title This is the initial image\n",
        "\n",
        "initial_image"
      ],
      "metadata": {
        "id": "_mb6lT-eYrkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run the Rorschach Recursion\n",
        "\n",
        "prompt = \"Describe in detail what you see in the image in 20 or fewer words.\" # @param {type:\"string\"}\n",
        "num_iterations = 5 # @param {type:\"integer\"}\n",
        "\n",
        "image_list = recursive_rorschach(initial_image, prompt, num_iterations)\n",
        "image_list.insert(0, {\"image\": initial_image, \"prompt\": \"(this is the initial image)\"})\n",
        "\n",
        "prompt_list = [image_dict['prompt'] for image_dict in image_list]\n",
        "\n",
        "# save all images to disk\n",
        "for i, image_dict in enumerate(image_list):\n",
        "    image_dict['image'].save(\"image_{}.png\".format(i))\n",
        "\n",
        "# save all prompts to text file\n",
        "with open('prompts.txt', 'w') as f:\n",
        "    for prompt in prompt_list:\n",
        "        f.write(prompt + '\\n')"
      ],
      "metadata": {
        "id": "tpEYSCgVW4Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create the video from the generated images\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Function to blend two images\n",
        "def blend_images(image1, image2, alpha):\n",
        "    return cv2.addWeighted(image1, alpha, image2, 1 - alpha, 0)\n",
        "\n",
        "# Load your images (assuming they are in the 'images' folder and are named sequentially)\n",
        "#image_files = [f'viterate_{i}.png' for i in range(num_iterations)]\n",
        "#images = [cv2.imread(f'{file}') for file in image_files]\n",
        "images = [cv2.cvtColor(np.array(pil_image['image']), cv2.COLOR_RGB2BGR) for pil_image in image_list]\n",
        "\n",
        "# Specify the number of steps in the transition\n",
        "transition_steps = 30\n",
        "\n",
        "# Initialize video writer\n",
        "frame_size = (images[0].shape[1], images[0].shape[0])\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "video = cv2.VideoWriter('output_video.mp4', fourcc, 20.0, frame_size)\n",
        "\n",
        "# Create transitions between images\n",
        "for i in range(len(images) - 1):\n",
        "    for step in range(int(transition_steps / 5)):\n",
        "        video.write(images[i])\n",
        "\n",
        "    # Cross-dissolve transition\n",
        "    for step in range(transition_steps):\n",
        "        alpha = step / transition_steps\n",
        "        transition_image = blend_images(images[i + 1], images[i], alpha)\n",
        "        video.write(transition_image)\n",
        "\n",
        "# Make sure to write the last image\n",
        "video.write(images[-1])\n",
        "\n",
        "# Release the video writer\n",
        "video.release()\n",
        "\n",
        "# show download link for video\n",
        "filename = 'output_video.mp4'\n",
        "files.download(filename)"
      ],
      "metadata": {
        "id": "SY9d5u4PKYQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download all images and prompts\n",
        "\n",
        "import zipfile\n",
        "import glob\n",
        "\n",
        "# Create a list of all prompt txt files\n",
        "prompt_files = glob.glob(\"prompts.txt\")\n",
        "\n",
        "# Create a list of all images\n",
        "image_files = glob.glob(\"image_*.png\")\n",
        "\n",
        "# Create a zip file\n",
        "with zipfile.ZipFile(\"output.zip\", \"w\") as zip_file:\n",
        "  # Add all prompt txt files to the zip file\n",
        "  for prompt_file in prompt_files:\n",
        "    zip_file.write(prompt_file)\n",
        "\n",
        "  # Add all images to the zip file\n",
        "  for image_file in image_files:\n",
        "    zip_file.write(image_file)\n",
        "\n",
        "# Make the zip file available for download\n",
        "files.download(\"output.zip\")"
      ],
      "metadata": {
        "id": "prvzCkAhQWQd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}